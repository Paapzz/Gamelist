#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import json
import time
import random
import difflib
from datetime import datetime
from pathlib import Path

from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
import requests

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEBUG_DUMPS = Path("debug_dumps")
DEBUG_DUMPS.mkdir(exist_ok=True)
DATA_DIR = Path("hltb_data")
DATA_DIR.mkdir(exist_ok=True)

HLTB_BASE = "https://howlongtobeat.com"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ›Ğ¾Ğ³Ğ³ĞµÑ€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log(msg: str):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def dump_json(data, filename):
    with open(DEBUG_DUMPS / filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def dump_html(content, filename):
    with open(DEBUG_DUMPS / filename, "w", encoding="utf-8") as f:
        f.write(content)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ñ€Ğ¾Ğº
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sanitize_query(q: str) -> str:
    q = q.replace("&", "and")
    q = re.sub(r"[/:()]", " ", q)
    q = re.sub(r"\s+", " ", q).strip()
    return q

def generate_search_variants(name: str):
    base = sanitize_query(name)
    variants = [base]

    # Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ /
    if "/" in base:
        parts = [p.strip() for p in base.split("/") if p.strip()]
        variants.extend(parts)

    # Ğ¦Ğ¸Ñ„Ñ€Ñ‹ Ğ² Ñ€Ğ¸Ğ¼ÑĞºĞ¸Ğµ
    variants = list(set(variants))
    return variants

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğ° HLTB
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_game_on_hltb(page, query: str):
    log(f"ğŸ” Ğ˜Ñ‰ĞµĞ¼: '{query}'")
    page.goto(f"{HLTB_BASE}/search_results?page=1&query={query}", timeout=60000)
    page.wait_for_timeout(2000)

    candidates = []
    try:
        rows = page.query_selector_all("li.back_gray.shadow_box")
        for row in rows:
            title_el = row.query_selector("a.text_blue")
            year_el = row.query_selector("div.search_list_tidbit")
            if not title_el:
                continue
            title = title_el.inner_text().strip()
            href = title_el.get_attribute("href")
            year = None
            if year_el:
                txt = year_el.inner_text().strip()
                m = re.search(r"\d{4}", txt)
                if m:
                    year = int(m.group(0))
            candidates.append({
                "title": title,
                "href": href,
                "year": year
            })
    except Exception as e:
        log(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²: {e}")

    dump_json(candidates, f"{query}_candidates_{int(time.time())}.json")
    log(f"ğŸ” ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²: {len(candidates)}")
    return candidates

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¸Ğ³Ñ€Ñ‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_game_times(page, game_url: str):
    url = f"{HLTB_BASE}{game_url}"
    page.goto(url, timeout=60000)
    page.wait_for_timeout(2000)

    html = page.content()
    dump_html(html, f"{Path(game_url).name}_game_{int(time.time())}.html")

    results = {}
    try:
        blocks = page.query_selector_all("div.GameStats_game_time__*")
        for b in blocks:
            text = b.inner_text().strip()
            if not text:
                continue
            if ":" in text:
                key, val = text.split(":", 1)
                results[key.strip()] = val.strip()
            else:
                parts = text.split()
                if len(parts) >= 2:
                    key = " ".join(parts[:-1])
                    val = parts[-1]
                    results[key.strip()] = val.strip()
    except Exception as e:
        log(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° Ğ¸Ğ³Ñ€Ñ‹ {url}: {e}")
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_game(page, title: str, year: int):
    variants = generate_search_variants(title)
    best_result = None
    best_score = 0.0

    for var in variants:
        candidates = search_game_on_hltb(page, var)
        if not candidates:
            continue

        # Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ³Ğ¾Ğ´Ñƒ
        filtered = [c for c in candidates if c["year"] == year]
        pool = filtered if filtered else candidates

        # Ğ¸Ñ‰ĞµĞ¼ Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞµĞµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ
        for cand in pool:
            score = difflib.SequenceMatcher(None, cand["title"].lower(), title.lower()).ratio()
            if score > best_score:
                best_score = score
                best_result = cand

        if best_score >= 0.95:
            break

    if best_result:
        log(f"ğŸ¯ Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ¾: '{best_result['title']}' (score {best_score:.2f})")
        times = extract_game_times(page, best_result["href"])
        return {
            "title": best_result["title"],
            "year": best_result["year"],
            "times": times
        }
    else:
        log(f"âš ï¸ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ´Ğ»Ñ: {title}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    log("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº HLTB Worker")
    games_list = [
        {"title": "Sonic the Hedgehog 3 (& Knuckles)", "year": 1994},
        {"title": "Ultima / Ultima I: The First Age of Darkness", "year": 1981},
        {"title": "Doom II", "year": 1994},
        {"title": "PokÃ©mon Red/Blue/Yellow", "year": 1996},
        {"title": "Tetris", "year": 1985},
        {"title": "Half-Life 2", "year": 2004},
        {"title": "God of War", "year": 2018},
    ]

    results = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        for idx, g in enumerate(games_list, 1):
            log(f"ğŸ® ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ {idx}/{len(games_list)}: {g['title']} ({g['year']})")
            result = process_game(page, g["title"], g["year"])
            if result:
                results.append(result)
            time.sleep(random.uniform(2, 4))

        browser.close()

    outfile = DATA_DIR / f"hltb_data_{int(time.time())}.json"
    with open(outfile, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    log(f"âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: {outfile}")

if __name__ == "__main__":
    main()
