# hltb_worker.py
# –í–µ—Ä—Å–∏—è: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ + –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–±–æ—Ä —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π + adaptive backoff
# –ó–∞–º–µ–Ω–∏—Ç–µ —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —ç—Ç–∏–º.
import json
import time
import random
import re
import os
from datetime import datetime
from urllib.parse import quote, unquote
from playwright.sync_api import sync_playwright

BASE_URL = "https://howlongtobeat.com"
GAMES_LIST_FILE = "index111.html"
OUTPUT_DIR = "hltb_data"
OUTPUT_FILE = f"{OUTPUT_DIR}/hltb_data.json"
PROGRESS_FILE = "progress.json"

# –¢–∞–π–º–∞—É—Ç—ã (—É–º–µ—Ä–µ–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –Ω–µ —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ —Å—á–∏—Ç–∞—Ç—å —Ç–∞–π–º–∞—É—Ç–∞–º–∏)
PAGE_GOTO_TIMEOUT = 30000
PAGE_LOAD_TIMEOUT = 20000

# Rate control: —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è throughput
# –î–ª—è 1000 –∏–≥—Ä –∑–∞ 6 —á–∞—Å–æ–≤ —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è ~21.6 —Å–µ–∫—É–Ω–¥/–∏–≥—Ä—É.
# –ú—ã —Ü–µ–ª–∏–º—Å—è –ø–æ—Ä—è–¥–∫–∞ 12-20 —Å–µ–∫/–∏–≥—Ä–∞ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏–∏.
MIN_DELAY = 0.6    # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏—è–º–∏
MAX_DELAY = 1.6    # –Ω–µ–±–æ–ª—å—à–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞ (—É—Å–∫–æ—Ä–µ–Ω–æ)
# –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞—Ö
INITIAL_BACKOFF = 5      # —Å–µ–∫—É–Ω–¥–∞ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –±—ç–∫–æ—Ñ—Ñ–∞ –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö
BACKOFF_MULTIPLIER = 2.0 # –º–Ω–æ–∂–∏—Ç–µ–ª—å –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–±–ª–µ–º–µ
MAX_BACKOFF = 300        # –º–∞–∫—Å–∏–º—É–º –±—ç–∫–æ—Ñ—Ñ–∞ 5 –º–∏–Ω—É—Ç

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è/–æ—Ç–ª–∞–¥–∫–∏
DEBUG_CANDIDATES = True  # –≤–∫–ª—é—á–∏—Ç–µ True –¥–ª—è –¥–∞–º–ø–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —Å–ø–æ—Ä–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
VERBOSE = True

def log_message(message):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] {message}")

def setup_directories():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

# -------------------- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏/—Å—Ä–∞–≤–Ω–µ–Ω–∏—è --------------------

def clean_title_for_comparison(title):
    if not title:
        return ""
    s = title
    s = s.replace('\u2018','\'').replace('\u2019','\'').replace('\u201c','"').replace('\u201d','"')
    s = s.lower()
    s = re.sub(r'\(.*?\)', ' ', s)         # —É–±–∏—Ä–∞–µ–º —Å–∫–æ–±–æ—á–Ω—ã–µ —á–∞—Å—Ç–∏ (—á–∞—Å—Ç–æ –ª–∏—à–Ω–∏–µ)
    s = re.sub(r'[\u2010-\u2015]', '-', s) # normalize dashes
    s = re.sub(r'[^0-9a-z–∞-—è—ë\s]', ' ', s) # —Ä–∞–∑—Ä–µ—à–∞–µ–º –±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø—Ä–æ–±–µ–ª (—Ä—É—Å—Å–∫–∏–µ –Ω–∞ —Å–ª—É—á–∞–π)
    s = re.sub(r'\s+', ' ', s).strip()
    return s

def normalize_title_for_comparison(title):
    if not title:
        return ""
    s = f" {title} "
    roman_to_arabic = {
        ' i ': ' 1 ', ' ii ': ' 2 ', ' iii ': ' 3 ', ' iv ': ' 4 ', ' v ': ' 5 ',
        ' vi ': ' 6 ', ' vii ': ' 7 ', ' viii ': ' 8 ', ' ix ': ' 9 ', ' x ': ' 10 '
    }
    for r,a in roman_to_arabic.items():
        s = s.replace(r, a)
    return s.strip()

def convert_arabic_to_roman(num_str):
    try:
        num = int(num_str)
        map_ = {1:"I",2:"II",3:"III",4:"IV",5:"V",6:"VI",7:"VII",8:"VIII",9:"IX",10:"X"}
        return map_.get(num, num_str)
    except:
        return num_str

def convert_roman_to_arabic(roman_str):
    try:
        roman_to_arabic_map = {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5,
                              'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10}
        return str(roman_to_arabic_map.get(roman_str.upper(), roman_str))
    except:
        return roman_str

def lcs_length(a_tokens, b_tokens):
    n, m = len(a_tokens), len(b_tokens)
    if n == 0 or m == 0:
        return 0
    dp = [[0] * (m + 1) for _ in range(n + 1)]
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if a_tokens[i-1] == b_tokens[j-1]:
                dp[i][j] = dp[i-1][j-1] + 1
            else:
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
    return dp[n][m]

def calculate_title_similarity(original, candidate):
    """
    –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞:
    - —Å–Ω–∞—á–∞–ª–∞ –±—ã—Å—Ç—Ä—ã–µ exact-—Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞ –æ—á–∏—â—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫–∞—Ö (–µ—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç -> 1.0)
    - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —á–∞—Å—Ç–∏ (–¥–æ ':') –¥–∞—ë—Ç —Å–∏–ª—å–Ω—ã–π –±—É—Å—Ç
    - –¥–∞–ª–µ–µ LCS/recall/precision –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    """
    if not original or not candidate:
        return 0.0
    try:
        orig_norm = clean_title_for_comparison(normalize_title_for_comparison(original))
        cand_norm = clean_title_for_comparison(normalize_title_for_comparison(candidate))
        # exact
        if orig_norm == cand_norm:
            return 1.0
        # try arabic <-> roman quick swaps on original (cover cases like 'III'/'3')
        m = re.search(r'\b(\d+)\b', original)
        if m:
            roman = convert_arabic_to_roman(m.group(1))
            if roman:
                if clean_title_for_comparison(normalize_title_for_comparison(re.sub(r'\b'+re.escape(m.group(1))+r'\b', roman, original))) == cand_norm:
                    return 1.0
        m2 = re.search(r'\b(I{1,3}|IV|V|VI{0,3}|IX|X)\b', original, flags=re.IGNORECASE)
        if m2:
            arab = convert_roman_to_arabic(m2.group(1))
            if arab:
                if clean_title_for_comparison(normalize_title_for_comparison(re.sub(r'\b'+re.escape(m2.group(1))+r'\b', arab, original))) == cand_norm:
                    return 1.0

        # base (before colon) boost
        base = original.split(":",1)[0].strip()
        base_norm = clean_title_for_comparison(normalize_title_for_comparison(base))
        if base_norm and base_norm == cand_norm:
            return 0.98  # –ø–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω–æ–µ

        # token-based metric
        a_tokens = orig_norm.split()
        b_tokens = cand_norm.split()
        if not a_tokens or not b_tokens:
            return 0.0
        common = set(a_tokens).intersection(set(b_tokens))
        precision = len(common) / len(b_tokens)
        recall = len(common) / len(a_tokens)
        lcs_len = lcs_length(a_tokens, b_tokens)
        seq = (lcs_len / len(a_tokens)) if len(a_tokens)>0 else 0.0
        score = 0.6 * recall + 0.25 * precision + 0.15 * seq
        return float(max(0.0, min(1.0, score)))
    except Exception:
        return 0.0

def generate_alternative_titles(game_title):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤: slash -> and/& combos, base before colon, roman/arabic variants."""
    if not game_title:
        return []
    seen = set()
    out = []
    def add(s):
        if not s: return
        s2 = re.sub(r'\s+', ' ', s).strip()
        if s2 and s2 not in seen:
            seen.add(s2); out.append(s2)
    add(game_title)
    # slash/comma separators
    if '/' in game_title or ',' in game_title:
        parts = [p.strip() for p in re.split(r'[\/,]', game_title) if p.strip()]
        for p in parts:
            add(p)
        if len(parts) >= 2:
            add(f"{parts[0]} and {parts[1]}")
            add(f"{parts[0]} & {parts[1]}")
        if len(parts) >= 3:
            add(f"{parts[0]} and {parts[1]} and {parts[2]}")
            add(f"{parts[0]} & {parts[1]} & {parts[2]}")
        add(game_title.split(":",1)[0].strip())
    else:
        base = game_title.split(":",1)[0].strip()
        add(base)
        add(game_title)
        m = re.search(r'\b(\d+)\b', game_title)
        if m:
            r = convert_arabic_to_roman(m.group(1))
            if r and r != m.group(1):
                add(re.sub(r'\b'+re.escape(m.group(1))+r'\b', r, game_title))
        rm = re.search(r'\b(I{1,3}|IV|V|VI{0,3}|IX|X)\b', game_title, flags=re.IGNORECASE)
        if rm:
            a = convert_roman_to_arabic(rm.group(1))
            if a and a != rm.group(1):
                add(re.sub(r'\b'+re.escape(rm.group(1))+r'\b', a, game_title, flags=re.IGNORECASE))
    return out

# ------------------ –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (speed improvement) ------------------

def scrape_game_link_candidates(page, max_candidates=80):
    """
    –ë—ã—Å—Ç—Ä–æ –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (href, text, context_text) —Å search-—Å—Ç—Ä–∞–Ω–∏—Ü—ã
    —Å –ø–æ–º–æ—â—å—é –æ–¥–Ω–æ–≥–æ evaluate -> —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ roundtrips.
    """
    try:
        script = f'''
        (els, maxc) => {{
            const out = [];
            for (let i=0;i<Math.min(els.length, maxc);i++) {{
                try {{
                    const e = els[i];
                    const href = e.getAttribute('href') || '';
                    const text = e.innerText || '';
                    const p = e.closest('li') || e.closest('div') || e.parentElement;
                    const ctx = p ? (p.innerText || '') : (e.parentElement ? e.parentElement.innerText : text);
                    out.push({{href, text, ctx}});
                }} catch(e) {{ /* ignore */ }}
            }}
            return out;
        }}
        '''
        raw = page.eval_on_selector_all('a[href^="/game/"]', script, max_candidates)
        # Normalize to Python list of dicts
        candidates = []
        for r in raw:
            if not r: continue
            href = r.get("href","") or ""
            txt = r.get("text","") or ""
            ctx = r.get("ctx","") or ""
            candidates.append({"href": href, "text": txt.strip(), "context": ctx.strip()})
        return candidates
    except Exception as e:
        # fallback: empty list
        return []

def get_year_from_context_text(ctx_text):
    """–ò—â–µ–º 4-–∑–Ω–∞—á–Ω—ã–π –≥–æ–¥ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ"""
    if not ctx_text:
        return None
    m = re.findall(r'(\b19\d{2}\b|\b20\d{2}\b)', ctx_text)
    if m:
        years = [int(x) for x in m]
        return min(years)
    return None

# ------------------ –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ------------------

def find_best_candidate(candidates, original_title, game_year=None):
    """
    candidates: list of dict {href,text,context}
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (candidate_dict, score) –∏–ª–∏ (None,0.0)
    –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º:
      - —Å–Ω–∞—á–∞–ª–∞ exact-clean —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
      - –∑–∞—Ç–µ–º base + year match
      - –∑–∞—Ç–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥
    """
    if not candidates:
        return None, 0.0
    orig_clean = clean_title_for_comparison(normalize_title_for_comparison(original_title))
    base_clean = clean_title_for_comparison(normalize_title_for_comparison(original_title.split(":",1)[0].strip()))
    is_slash = '/' in original_title or ',' in original_title
    # prepare slash parts
    slash_parts = []
    if is_slash:
        raw_parts = [p.strip() for p in re.split(r'[\/,]', original_title) if p.strip()]
        slash_parts = [clean_title_for_comparison(p) for p in raw_parts]

    best = None
    best_score = -1.0

    # 1) exact-clean search (fast)
    for cand in candidates:
        ct = clean_title_for_comparison(normalize_title_for_comparison(cand["text"]))
        if ct == orig_clean:
            return cand, 1.0

    # 2) base + year quick win
    if game_year:
        for cand in candidates:
            ct = clean_title_for_comparison(normalize_title_for_comparison(cand["text"]))
            if base_clean and base_clean in ct:
                cy = get_year_from_context_text(cand.get("context",""))
                if cy and cy == game_year:
                    return cand, 0.999

    # 3) scoring loop
    for cand in candidates:
        cand_text = cand.get("text","")
        cand_ctx = cand.get("context","")
        # compute similarity
        score = calculate_title_similarity(original_title, cand_text)
        # year score boost
        if game_year:
            cy = get_year_from_context_text(cand_ctx)
            if cy:
                if cy == game_year:
                    score = max(score, 0.9)
                else:
                    diff = abs(game_year - cy)
                    if diff <= 2:
                        score = max(score, 0.75)
        # base containment boost
        ct = clean_title_for_comparison(normalize_title_for_comparison(cand_text))
        if base_clean and base_clean in ct:
            score += 0.06

        # slash handling: require minimal matching parts
        if is_slash:
            parts_matched = 0
            for p in slash_parts:
                if p and all(tok in ct for tok in p.split()):
                    parts_matched += 1
            min_req = max(1, (len(slash_parts)+1)//2)  # ceil(N/2)
            if parts_matched < min_req:
                score -= 0.45  # penalty for not matching enough parts

        if score > best_score:
            best_score = score
            best = cand

    # threshold to accept
    if best and best_score >= 0.25:
        return best, float(max(0.0, min(1.0, best_score)))
    return None, 0.0

# ------------------ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ HLTB-–¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ------------------

def round_time(time_str):
    if not time_str:
        return None
    s = str(time_str).replace('¬Ω', '.5')
    m = re.search(r'(\d+(?:\.\d+)?)\s*h', s, flags=re.IGNORECASE)
    if m:
        val = float(m.group(1))
        return f"{int(val)}h" if val == int(val) else f"{val:.1f}h"
    m = re.search(r'(\d+(?:\.\d+)?)\s*hours?', s, flags=re.IGNORECASE)
    if m:
        val = float(m.group(1))
        return f"{int(val)}h" if val == int(val) else f"{val:.1f}h"
    m = re.search(r'(\d+)\s*m', s, flags=re.IGNORECASE)
    if m:
        return f"{int(m.group(1))}m"
    m = re.search(r'(\d+(?:\.\d+)?)', s)
    if m:
        val = float(m.group(1))
        if val >= 1:
            return f"{int(val)}h" if val == int(val) else f"{val:.1f}h"
        return f"{int(val*60)}m"
    return None

def extract_hltb_data_from_page(page):
    """
    –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å —Ç–∞—Ä–≥–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–≥—Ä—ã.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–±–ª–∏—Ü—ã -> —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ -> fallback regex.
    """
    try:
        hltb_data = {}
        content = page.content()

        # 1) –¢–∞–±–ª–∏—Ü—ã
        try:
            tables = page.locator("table")
            for ti in range(tables.count()):
                tbl = tables.nth(ti)
                ttxt = tbl.inner_text()
                if any(k in ttxt for k in ["Main Story","Main + Extras","Completionist","Co-Op","Vs.","Competitive","Single-Player"]):
                    rows = tbl.locator("tr")
                    for ri in range(rows.count()):
                        rtxt = rows.nth(ri).inner_text()
                        if "Main Story" in rtxt or "Single-Player" in rtxt:
                            d = _parse_time_polled_from_text(rtxt)
                            if d: hltb_data["ms"] = d
                        if "Main + Extras" in rtxt:
                            d = _parse_time_polled_from_text(rtxt)
                            if d: hltb_data["mpe"] = d
                        if "Completionist" in rtxt:
                            d = _parse_time_polled_from_text(rtxt)
                            if d: hltb_data["comp"] = d
                        if "Co-Op" in rtxt:
                            d = _parse_time_polled_from_text(rtxt)
                            if d: hltb_data["coop"] = d
                        if "Vs." in rtxt or "Competitive" in rtxt:
                            d = _parse_time_polled_from_text(rtxt)
                            if d: hltb_data["vs"] = d
        except Exception:
            pass

        # 2) –ë–ª–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ (Co-Op, Vs., Single-Player)
        try:
            for keyword, key in [("Vs.", "vs"), ("Co-Op", "coop"), ("Single-Player", "ms")]:
                elems = page.locator(f"text={keyword}")
                for i in range(min(elems.count(), 6)):
                    try:
                        el = elems.nth(i)
                        surrounding = el.evaluate("(e) => (e.closest('div') || e.parentElement || e).innerText")
                        if key == "vs" and "vs" not in hltb_data:
                            m = re.search(r'(?:Vs\.|Versus)[^\d]{0,40}?(\d+(?:\.\d+)?(?:¬Ω)?)', surrounding, flags=re.IGNORECASE)
                            if m:
                                hltb_data["vs"] = {"t": round_time(m.group(1))}
                        if key == "coop" and "coop" not in hltb_data:
                            m = re.search(r'Co-Op[^\d]{0,40}?(\d+(?:\.\d+)?(?:¬Ω)?)', surrounding, flags=re.IGNORECASE)
                            if m:
                                hltb_data["coop"] = {"t": round_time(m.group(1))}
                        if key == "ms" and "ms" not in hltb_data:
                            m = re.search(r'(?:Single-Player|Main Story)[^\d]{0,40}?(\d+(?:\.\d+)?(?:¬Ω)?)', surrounding, flags=re.IGNORECASE)
                            if m:
                                hltb_data["ms"] = {"t": round_time(m.group(1))}
                    except Exception:
                        continue
        except Exception:
            pass

        # 3) Fallback regex –ø–æ HTML —Ü–µ–ª–∏–∫–æ–º
        if not hltb_data:
            patterns = {
                "ms": r'(?:Main Story|Single-Player)[^\n]{0,160}?(\d+(?:\.\d+)?(?:¬Ω)?\s*h?)',
                "mpe": r'(?:Main \+ Extras)[^\n]{0,160}?(\d+(?:\.\d+)?(?:¬Ω)?\s*h?)',
                "comp": r'(?:Completionist)[^\n]{0,160}?(\d+(?:\.\d+)?(?:¬Ω)?\s*h?)',
                "coop": r'(?:Co-Op)[^\n]{0,160}?(\d+(?:\.\d+)?(?:¬Ω)?\s*h?)',
                "vs": r'(?:Vs\.|Versus)[^\n]{0,160}?(\d+(?:\.\d+)?(?:¬Ω)?\s*h?)'
            }
            for k, p in patterns.items():
                m = re.search(p, content, flags=re.IGNORECASE)
                if m:
                    hltb_data[k] = {"t": round_time(m.group(1))}

        # stores
        stores = {}
        try:
            for name, sel in [("steam","a[href*='store.steampowered.com']"), ("gog","a[href*='gog.com']"), ("epic","a[href*='epicgames.com']")]:
                loc = page.locator(sel)
                if loc.count() > 0:
                    href = loc.first.get_attribute("href")
                    if href:
                        stores[name] = href
        except Exception:
            pass
        if stores:
            hltb_data["stores"] = stores

        return hltb_data if hltb_data else None
    except Exception as e:
        log_message(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return None

def _parse_time_polled_from_text(text):
    """–ü–∞—Ä—Å–µ—Ä —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã: –∏—â–µ—Ç –ø–µ—Ä–≤–æ–µ –≤—Ä–µ–º—è –∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) polled"""
    try:
        polled = None
        pm = re.search(r'(\d+(?:\.\d+)?[Kk]?)\s*(?:Polled|polled)?', text)
        if pm:
            s = pm.group(1)
            if 'k' in s.lower():
                polled = int(float(s.lower().replace('k','')) * 1000)
            else:
                polled = int(float(s))
        # –ø–µ—Ä–≤–æ–µ –≤—Ä–µ–º—è
        time_pat = r'(\d+h\s*\d+m|\d+h|\d+(?:\.\d+)?\s*Hours?|\d+(?:\.\d+)?[¬Ω]?)'
        matches = re.findall(time_pat, text)
        if matches:
            avg = matches[0].strip()
            res = {}
            t = round_time(avg)
            if t:
                res["t"] = t
            if polled:
                res["p"] = polled
            return res if res else None
        if polled:
            return {"p": polled}
        return None
    except Exception as e:
        return None

# ------------------ Search attempt + adaptive backoff ------------------

def random_delay(min_s=MIN_DELAY, max_s=MAX_DELAY):
    time.sleep(random.uniform(min_s, max_s))

def search_game_single_attempt(page, game_title, game_year=None, backoff=0):
    """
    –û–¥–Ω–∞ –ø–æ–ø—ã—Ç–∫–∞ –ø–æ–∏—Å–∫–∞: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç scrape_game_link_candidates –¥–ª—è –±—ã—Å—Ç—Ä–æ–¥–µ–π—Å—Ç–≤–∏—è.
    backoff ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ (—Å–µ–∫) –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞—Ö).
    """
    try:
        if backoff > 0:
            log_message(f"‚è≥ Backoff {backoff}s –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π –ø–æ–∏—Å–∫–∞ '{game_title}'")
            time.sleep(backoff)

        safe_title = quote(game_title, safe="")
        search_url = f"{BASE_URL}/?q={safe_title}"

        page.goto(search_url, timeout=PAGE_GOTO_TIMEOUT)
        page.wait_for_load_state("domcontentloaded", timeout=PAGE_LOAD_TIMEOUT)
        random_delay()

        page_content = page.content()
        if "blocked" in page_content.lower() or "access denied" in page_content.lower() or ("checking your browser" in page_content.lower() and "cloudflare" in page_content.lower()):
            log_message("‚ùå –í–æ–∑–º–æ–∂–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)")
            return None, "blocked"

        candidates = scrape_game_link_candidates(page, max_candidates=80)
        if DEBUG_CANDIDATES and VERBOSE:
            log_message(f"üîé –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(candidates)}")

        if len(candidates) > 30:
            # –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –∫–∞–≤—ã—á–∫–∞—Ö (–±—ã—Å—Ç—Ä—ã–π –ø–æ–≤—Ç–æ—Ä)
            quoted = f'"{game_title}"'
            page.goto(f"{BASE_URL}/?q={quote(quoted, safe='')}", timeout=PAGE_GOTO_TIMEOUT)
            page.wait_for_load_state("domcontentloaded", timeout=PAGE_LOAD_TIMEOUT)
            random_delay()
            page_content = page.content()
            if "blocked" in page_content.lower() or "access denied" in page_content.lower():
                return None, "blocked"
            candidates = scrape_game_link_candidates(page, max_candidates=80)

        if not candidates:
            return None, None

        best_cand, score = find_best_candidate(candidates, game_title, game_year)
        # Debug print of candidates if ambiguous
        if DEBUG_CANDIDATES and VERBOSE:
            if best_cand is None or score < 0.95:
                dump = [{"text": c["text"], "href": c["href"], "year": get_year_from_context_text(c["context"])} for c in candidates[:20]]
                log_message(f"üîç –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–æ–±—Ä–µ–∑–∫–∞): {json.dumps(dump, ensure_ascii=False)[:800]}")

        if not best_cand:
            return None, None

        # –ù–∞–≤–∏–≥–∞—Ü–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥)
        href = best_cand.get("href")
        if not href:
            return None, None
        full_url = f"{BASE_URL}{href}"
        page.goto(full_url, timeout=PAGE_GOTO_TIMEOUT)
        page.wait_for_load_state("domcontentloaded", timeout=PAGE_LOAD_TIMEOUT)
        random_delay()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏–≥—Ä—ã
        page_content = page.content()
        if "blocked" in page_content.lower() or "access denied" in page_content.lower():
            return None, "blocked"

        hltb_data = extract_hltb_data_from_page(page)
        if hltb_data:
            return (hltb_data, best_cand["text"], score), None
        else:
            return None, None
    except Exception as e:
        log_message(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ search_game_single_attempt –¥–ª—è '{game_title}': {e}")
        return None, None

def search_game_on_hltb(page, game_title, game_year=None, backoff_base=0):
    """
    –†–µ—Ç—Ä–∞–π–ª–æ–≥–∏–∫–∞ —Å adaptive backoff.
    backoff_base ‚Äî —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ backoff (—Å–µ–∫) –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫; –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (result, new_backoff)
    """
    max_attempts = 3
    backoff = backoff_base
    best_result = None
    best_score = 0.0

    for attempt in range(max_attempts):
        if attempt > 0:
            # –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞; –µ—Å–ª–∏ backoff –∑–∞–¥–∞–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if backoff > 0:
                delay = backoff
            else:
                delay = random.uniform(3, 6) if attempt == 1 else random.uniform(6, 12)
            log_message(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_attempts} –¥–ª—è '{game_title}' ‚Äî –ø–∞—É–∑–∞ {int(delay)}s")
            time.sleep(delay)

        result, status = search_game_single_attempt(page, game_title, game_year, backoff=0 if status_not_block(status:=None) else 0)
        # note: status variable set by function; to keep code safe we detect above via return tuple

        # search_game_single_attempt returns either ((hltb_data, found_title, score), None) or (None, "blocked"/None)
        if isinstance(result, tuple) and result:
            # success
            hltb, found_title, score = result
            # perfect match if score >= 0.98
            if score >= 0.98:
                log_message(f"üéØ –ù–∞–π–¥–µ–Ω–æ –∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{found_title}' (score {score:.2f})")
                return hltb, 0  # reset backoff on success
            # keep best
            if score > best_score:
                best_score = score
                best_result = hltb
            # if reasonable, return
            if score >= 0.7:
                return hltb, 0
            # otherwise, try alternatives
        else:
            # result is None; status maybe "blocked"
            if status == "blocked":
                # increase backoff
                backoff = max(backoff_base * BACKOFF_MULTIPLIER if backoff_base>0 else INITIAL_BACKOFF, INITIAL_BACKOFF)
                backoff = min(backoff, MAX_BACKOFF)
                log_message(f"üö´ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ ‚Äî —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º backoff –¥–æ {int(backoff)}s")
                # Sleep a bit before next attempt
                time.sleep(backoff)
                continue
            # else try alternatives
        # alternatives
        alts = generate_alternative_titles(game_title)
        for alt in alts:
            if alt == game_title:
                continue
            # small quick attempts for alternatives
            res, st = search_game_single_attempt(page, alt, game_year)
            if isinstance(res, tuple) and res:
                hltb, found_title, score = res
                if score >= 0.98:
                    log_message(f"üéØ –ù–∞–π–¥–µ–Ω –∏–¥–µ–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã '{alt}': '{found_title}'")
                    return hltb, 0
                if score > best_score:
                    best_score = score
                    best_result = hltb
            elif st == "blocked":
                backoff = max(backoff_base*BACKOFF_MULTIPLIER if backoff_base>0 else INITIAL_BACKOFF, INITIAL_BACKOFF)
                backoff = min(backoff, MAX_BACKOFF)
                log_message(f"üö´ –ë–ª–æ–∫ –ø—Ä–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–º –ø–æ–∏—Å–∫–µ ‚Äî backoff -> {int(backoff)}s")
                time.sleep(backoff)
                continue

    if best_result:
        log_message(f"üèÜ –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (score {best_score:.2f})")
        return best_result, max(0, backoff)
    return None, max(0, backoff)

def status_not_block(s):
    return s != "blocked"

# ------------------ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/—É—Ç–∏–ª–∏—Ç—ã ------------------

def save_results(games_data):
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for i, game in enumerate(games_data):
            if i > 0:
                f.write("\n")
            json.dump(game, f, separators=(',', ':'), ensure_ascii=False)
    log_message(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUTPUT_FILE}")

def save_progress(games_data, current_index, total_games):
    progress_data = {
        "current_index": current_index,
        "total_games": total_games,
        "last_updated": datetime.now().isoformat()
    }
    with open(PROGRESS_FILE, "w", encoding="utf-8") as f:
        json.dump(progress_data, f, ensure_ascii=False, indent=2)

def update_html_with_hltb(html_file, hltb_data):
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()
        start = content.find('const gamesList = ')
        if start == -1:
            return False
        start = content.find('[', start)
        bracket_count = 0
        end = start
        for i,ch in enumerate(content[start:], start):
            if ch == '[': bracket_count += 1
            elif ch == ']':
                bracket_count -= 1
                if bracket_count == 0:
                    end = i+1
                    break
        new = content[:start] + json.dumps(hltb_data, ensure_ascii=False) + content[end:]
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(new)
        return True
    except Exception as e:
        log_message(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è HTML: {e}")
        return False

# ------------------ main: loop + adaptive backoff control ------------------

def main():
    log_message("üöÄ –ó–∞–ø—É—Å–∫ HLTB Worker (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    if not os.path.exists(GAMES_LIST_FILE):
        log_message(f"‚ùå –§–∞–π–ª {GAMES_LIST_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    setup_directories()
    with open(GAMES_LIST_FILE, "r", encoding="utf-8") as f:
        content = f.read()
    # –∏–∑–≤–ª–µ–∫–∞–µ–º gamesList –º–∞—Å—Å–∏–≤
    start = content.find('const gamesList = ')
    if start == -1:
        log_message("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω gamesList –≤ HTML")
        return
    start = content.find('[', start)
    bracket_count = 0
    end = start
    for i,ch in enumerate(content[start:], start):
        if ch == '[': bracket_count += 1
        elif ch == ']':
            bracket_count -= 1
            if bracket_count == 0:
                end = i+1
                break
    games_list = json.loads(content[start:end])
    total_games = len(games_list)
    log_message(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–æ {total_games} –∏–≥—Ä")

    start_index = 0
    if os.path.exists(PROGRESS_FILE):
        try:
            with open(PROGRESS_FILE, "r", encoding="utf-8") as f:
                prog = json.load(f)
            start_index = prog.get("current_index", 0)
            log_message(f"üìÇ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø–æ–∑–∏—Ü–∏–∏ {start_index}")
        except:
            start_index = 0

    backoff_state = 0  # —Ö—Ä–∞–Ω–∏—Ç —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ backoff (—Å–µ–∫)

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36",
            viewport={"width":1280, "height":800},
            locale="en-US"
        )
        page = context.new_page()
        try:
            page.goto(BASE_URL, timeout=PAGE_GOTO_TIMEOUT)
            page.wait_for_load_state("domcontentloaded", timeout=PAGE_LOAD_TIMEOUT)
            log_message("‚úÖ HowLongToBeat –¥–æ—Å—Ç—É–ø–µ–Ω")
        except Exception as e:
            log_message(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–∞–π—Ç–∞: {e}")

        start_time = time.time()
        processed = 0
        for i in range(start_index, total_games):
            game = games_list[i]
            title = game.get("title") or ""
            year = game.get("year")
            log_message(f"üéÆ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {i+1}/{total_games}: {title} ({year})")

            hltb_data, new_backoff = search_game_on_hltb(page, title, year, backoff_base=backoff_state)
            # update backoff state: if new_backoff > 0 -> set it; otherwise decay
            if new_backoff and new_backoff > backoff_state:
                backoff_state = new_backoff
            else:
                # gentle decay of backoff when things good
                backoff_state = max(0, backoff_state * 0.6)

            if hltb_data:
                game["hltb"] = hltb_data
                processed += 1
                log_message(f"‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è '{title}'")
            else:
                game["hltb"] = {"ms":"N/A","mpe":"N/A","comp":"N/A","all":"N/A"}
                log_message(f"‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è: {title} - –∑–∞–ø–∏—Å–∞–Ω–æ N/A")

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
            if (i+1) % 25 == 0:
                save_progress(games_list, i+1, total_games)
            # –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–∞–ª–µ–Ω—å–∫–∞—è –ø–∞—É–∑–∞ (–µ—Å–ª–∏ backoff_state –±–æ–ª—å—à–æ–π ‚Äî —É—Ö–æ–¥–∏–º –≤ sleep)
            if backoff_state >= 30:
                log_message(f"‚è∏Ô∏è –ñ–¥–µ–º backoff_state {int(backoff_state)}s –∏–∑-–∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—à–∏–±–æ–∫/–±–ª–æ–∫–∏—Ä–æ–≤–æ–∫")
                time.sleep(backoff_state)
            else:
                random_delay()

        browser.close()

    save_results(games_list)
    if update_html_with_hltb(GAMES_LIST_FILE, games_list):
        log_message("‚úÖ HTML —Ñ–∞–π–ª –æ–±–Ω–æ–≤–ª—ë–Ω")
    log_message(f"üéâ –ì–æ—Ç–æ–≤–æ ‚Äî –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{total_games} –∏–≥—Ä")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        log_message(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise
